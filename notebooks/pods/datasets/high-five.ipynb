{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Five Motion Capture Dataset\n",
    "================================\n",
    "\n",
    "### [Neil D. Lawrence](http://inverseprobability.com), University of\n",
    "\n",
    "Cambridge\n",
    "\n",
    "### 2020-11-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "-----\n",
    "\n",
    "First we download some libraries and files to support the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mlai.py', <http.client.HTTPMessage at 0x1080310b8>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/mlai.py','mlai.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('teaching_plots.py', <http.client.HTTPMessage at 0x108031748>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/teaching_plots.py','teaching_plots.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gp_tutorial.py', <http.client.HTTPMessage at 0x108031ba8>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/gp_tutorial.py','gp_tutorial.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--setupplotcode{import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('paper')\n",
    "sns.set_palette('colorblind')}-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pods\n",
    "----\n",
    "\n",
    "In Sheffield we created a suite of software tools for ‘Open Data\n",
    "Science’. Open data science is an approach to sharing code, models and\n",
    "data that should make it easier for companies, health professionals and\n",
    "scientists to gain access to data science techniques.\n",
    "\n",
    "You can also check this blog post on [Open Data\n",
    "Science](http://inverseprobability.com/2014/07/01/open-data-science).\n",
    "\n",
    "The software can be installed using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/sods/ods\n",
      "  Cloning https://github.com/sods/ods to /private/var/folders/22/6ls22g994bdfdpwx4f9gcmsw0000gn/T/pip-req-build-d86gdokp\n",
      "  Running command git clone -q https://github.com/sods/ods /private/var/folders/22/6ls22g994bdfdpwx4f9gcmsw0000gn/T/pip-req-build-d86gdokp\n",
      "Building wheels for collected packages: pods\n",
      "  Building wheel for pods (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pods: filename=pods-0.0.21a0-py3-none-any.whl size=72910 sha256=93bbf508a9d097879b76f8d5daf1b301dc43d6b18a32eef68bddb1f04319fe68\n",
      "  Stored in directory: /private/var/folders/22/6ls22g994bdfdpwx4f9gcmsw0000gn/T/pip-ephem-wheel-cache-yhnyepa1/wheels/56/7f/87/0040ccbdd4956090a84a27ce7652170066c3ba2fc4078a892d\n",
      "Successfully built pods\n",
      "Installing collected packages: pods\n",
      "  Attempting uninstall: pods\n",
      "    Found existing installation: pods 0.0.21a0\n",
      "    Uninstalling pods-0.0.21a0:\n",
      "      Successfully uninstalled pods-0.0.21a0\n",
      "Successfully installed pods-0.0.21a0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade git+https://github.com/sods/ods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the command prompt where you can access your python installation.\n",
    "\n",
    "The code is also available on github:\n",
    "<a href=\"https://github.com/sods/ods\" class=\"uri\">https://github.com/sods/ods</a>\n",
    "\n",
    "Once `pods` is installed, it can be imported in the usual manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‘High Five’ Motion Capture Data\n",
    "-------------------------------\n",
    "\n",
    "Motion capture data from the CMU motion capture data base (CMU Motion\n",
    "Capture Lab, 2003). It contains two subjects approaching each other and\n",
    "executing a ‘high five’. The subjects are number 10 and 11 and their\n",
    "motion numbers are 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring resource: cmu_mocap\n",
      "\n",
      "Details of data: \n",
      "CMU Motion Capture data base. Captured by a Vicon motion capture system consisting of 12 infrared MX-40 cameras, each of which is capable of recording at 120 Hz with images of 4 megapixel resolution. Motions are captured in a working volume of approximately 3m x 8m. The capture subject wears 41 markers and a stylish black garment.\n",
      "\n",
      "Please cite:\n",
      "Please include this in your acknowledgements: The data used in this project was obtained from mocap.cs.cmu.edu.\\nThe database was created with funding from NSF EIA-0196217.\n",
      "\n",
      "Data will be stored in /Users/neil/ods_data_cache/cmu_mocap.\n",
      "\n",
      "You must also agree to the following license:\n",
      "From http://mocap.cs.cmu.edu. This data is free for use in research projects. You may include this data in commercially-sold products, but you may not resell this data directly, even in converted form. If you publish results obtained using this data, we would appreciate it if you would send the citation to your published paper to jkh+mocap@cs.cmu.edu, and also would add this text to your acknowledgments section: The data used in this project was obtained from mocap.cs.cmu.edu. The database was created with funding from NSF EIA-0196217.\n",
      "\n",
      "Do you wish to proceed with the download? [yes/no]\n",
      "yes\n",
      "Downloading  http://mocap.cs.cmu.edu/subjects/20/20.asf -> /Users/neil/ods_data_cache/cmu_mocap/20.asf\n",
      "|    Downloading   0.007MB     |\n",
      "|>|\n",
      "Downloading  http://mocap.cs.cmu.edu/subjects/20/20_11.amc -> /Users/neil/ods_data_cache/cmu_mocap/20_11.amc\n",
      "|    Downloading   0.177MB     |\n",
      "|>>>>>>>>>>>>>>>>>>>>>>>|\n",
      "Acquiring resource: cmu_mocap\n",
      "\n",
      "Details of data: \n",
      "CMU Motion Capture data base. Captured by a Vicon motion capture system consisting of 12 infrared MX-40 cameras, each of which is capable of recording at 120 Hz with images of 4 megapixel resolution. Motions are captured in a working volume of approximately 3m x 8m. The capture subject wears 41 markers and a stylish black garment.\n",
      "\n",
      "Please cite:\n",
      "Please include this in your acknowledgements: The data used in this project was obtained from mocap.cs.cmu.edu.\\nThe database was created with funding from NSF EIA-0196217.\n",
      "\n",
      "Data will be stored in /Users/neil/ods_data_cache/cmu_mocap.\n",
      "\n",
      "You must also agree to the following license:\n",
      "From http://mocap.cs.cmu.edu. This data is free for use in research projects. You may include this data in commercially-sold products, but you may not resell this data directly, even in converted form. If you publish results obtained using this data, we would appreciate it if you would send the citation to your published paper to jkh+mocap@cs.cmu.edu, and also would add this text to your acknowledgments section: The data used in this project was obtained from mocap.cs.cmu.edu. The database was created with funding from NSF EIA-0196217.\n",
      "\n",
      "Do you wish to proceed with the download? [yes/no]\n",
      "yes\n",
      "Downloading  http://mocap.cs.cmu.edu/subjects/21/21.asf -> /Users/neil/ods_data_cache/cmu_mocap/21.asf\n",
      "|    Downloading   0.007MB     |\n",
      "|>|\n",
      "Downloading  http://mocap.cs.cmu.edu/subjects/21/21_11.amc -> /Users/neil/ods_data_cache/cmu_mocap/21_11.amc\n",
      "|    Downloading   0.177MB     |\n",
      "|>>>>>>>>>>>>>>>>>>>>>>>|\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resource' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b3e7dcb38539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmu_mocap_high_five\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pods/datasets.py\u001b[0m in \u001b[0;36mcmu_mocap_high_five\u001b[0;34m(data_set)\u001b[0m\n\u001b[1;32m   1531\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmu_mocap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'11'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmu_mocap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'21'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'11'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m     \u001b[0mdata_resources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m     \u001b[0mdata_resources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'urls'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'urls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resource' is not defined"
     ]
    }
   ],
   "source": [
    "data = pods.datasets.cmu_mocap_high_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary contains the keys ‘Y1’ and ‘Y2’, which represent the\n",
    "motions of the two different subjects. Their skeleton files are included\n",
    "in the keys ‘skel1’ and ‘skel2’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['X'].shape\n",
    "data['Y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally there are keys `Xtest` and `Ytest` which provide test data.\n",
    "The number of points considered to be *training data* is controlled by\n",
    "the argument `num_train` argument, which defaults to 700,000. This\n",
    "number is chosen as it matches that used in the Gaussian Processes for\n",
    "Big Data paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Y1'].shape\n",
    "data['Y2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was used in the hierarchical GP-LVM paper (Lawrence and Moore,\n",
    "2007) in an experiment that was also recreated in the Deep Gaussian\n",
    "process paper (Damianou and Lawrence, 2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['citation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And extra information about the data is included, as standard, under the\n",
    "keys `info` and `details`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['info'])\n",
    "print()\n",
    "print(data['details'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMU Motion Capture Lab, 2003. The cmu mocap database.\n",
    "\n",
    "Damianou, A., Lawrence, N.D., 2013. Deep Gaussian processes, in:. pp.\n",
    "207–215.\n",
    "\n",
    "Lawrence, N.D., Moore, A.J., 2007. Hierarchical Gaussian process latent\n",
    "variable models, in:. pp. 481–488."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
